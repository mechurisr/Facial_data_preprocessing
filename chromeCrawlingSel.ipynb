{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###준비물: \n",
    "1. Chromedriver (https://chromedriver.storage.googleapis.com/index.html?path=84.0.4147.30/\n",
    "2.selenium\n",
    "3.opencv (haarcascade_eye, haarcascade_frontalface_default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  urllib.request\n",
    "\n",
    "from  bs4  import  BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "import time\n",
    "\n",
    " \n",
    "\n",
    "binary = 'chromedriver_win32/chromedriver.exe'\n",
    "\n",
    "browser = webdriver.Chrome(binary)\n",
    "\n",
    "browser.get(\"https://www.google.co.kr/imghp?hl=ko\")\n",
    "\n",
    "elem = browser.find_element_by_class_name(\"gLFyf\") #검색창 id\n",
    "\n",
    " \n",
    "\n",
    "# find_elements_by_class_name(\"\")\n",
    "\n",
    " \n",
    "\n",
    "# 검색어 입력\n",
    "\n",
    " \n",
    "\n",
    "elem.send_keys(\"neutral+face+real+photo\")\n",
    "\n",
    "elem.submit()\n",
    "\n",
    " \n",
    "\n",
    "# 반복할 횟수\n",
    "\n",
    " \n",
    "\n",
    "for i in range(1 ,10):\n",
    "\n",
    "    browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)\n",
    "\n",
    "#모두의 코드와 동일한데 거기다 try,except 하나 추가했음\n",
    "\n",
    "    try:\n",
    "\n",
    "        browser.find_element_by_id(\"smb\").click()\n",
    "\n",
    "         #smb는 결과더보기. 그걸 클릭!\n",
    "\n",
    "        #사진 뽑다보면\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "    except:\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "html = browser.page_source\n",
    "\n",
    "soup = BeautifulSoup(html ,\"html.parser\")\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "def fetch_list_url():\n",
    "\n",
    "    params = []\n",
    "\n",
    "    imgList = soup.find_all(\"img\", class_ =\"rg_i Q4LuWd\")\n",
    "\n",
    " \n",
    "\n",
    "    for im in imgList:\n",
    "\n",
    "        try:\n",
    "\n",
    "            params.append(im[\"src\"])\n",
    "\n",
    "        except KeyError:\n",
    "\n",
    "            params.append(im[\"data-src\"])\n",
    "        \n",
    "        except HTTPError:\n",
    "            \n",
    "            break\n",
    "            \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    return params\n",
    "\n",
    " \n",
    "\n",
    "def  fetch_detail_url():\n",
    "    params = fetch_list_url()\n",
    "    # print(params)\n",
    "\n",
    " \n",
    "\n",
    "    a = 1\n",
    "\n",
    " \n",
    "\n",
    "    for p in params:\n",
    "\n",
    "        # 다운받을 폴더경로 입력\n",
    "\n",
    "        urllib.request.urlretrieve(p, \"C:\\\\dev\\\\eclipse-workspace\\\\Python_Basic\\\\faceCrawling\\\\neutral+face+real+photo/a\"+ str(a) + \".jpg\" )\n",
    "\n",
    "        a+=1\n",
    "\n",
    " \n",
    "\n",
    "fetch_detail_url()\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2는 python에서 사용할 수 있는 opencv 모듈입니다.\n",
    "import cv2\n",
    "\n",
    "#불러올 이미지 파일의 경로\n",
    "imageFile1 = 'happy+face+real+photo/ 1.jpg'\n",
    "imageFile2 = 'happy+face+real+photo/ 2.jpg'\n",
    "\n",
    "#이미지를 불러옵니다.\n",
    "imgArray1 = cv2.imread(imageFile1)\n",
    "imgArray2 = cv2.imread(imageFile2, 0) #cv2.imread(imageFile2, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 얼굴 Crop 하여 저장1 (OpenCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_casecade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('C:\\\\dev\\\\eclipse-workspace\\\\Python_Basic\\\\faceCrawling\\\\sad+facial+expression\\\\ 4.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3,5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0),2)\n",
    "    cropped = img[y - int(h/4):y + h + int(h/4), x - int(w/4):x + w + int(w/4)]\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_casecade.detectMultiScale(roi_gray)\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh),(0,255,0),2)\n",
    "\n",
    "cv2.imshow('Image view', cropped)\n",
    "#cv2.imwrite('cropped/ 12.jpg', cropped)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼굴 Crop 하여 저장(사진만)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_casecade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('C:\\\\dev\\\\eclipse-workspace\\\\Python_Basic\\\\faceCrawling\\\\happy+face+real+photo\\\\ 12.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3,5)\n",
    "imgNum  = 0\n",
    "for (x,y,w,h) in faces:\n",
    "    cropped = img[y - int(h / 4):y + h + int(h / 4), x - int(w / 4):x + w + int(w / 4)]\n",
    "    # 이미지를 저장\n",
    "    cv2.imwrite('cropped/ 12.jpg', cropped)\n",
    "    imgNum += 1\n",
    "    # 얼굴인식표시\n",
    "    #cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0),2)\n",
    "    # roi_gray = gray[y:y+h, x:x+w]\n",
    "    # roi_color = img[y:y+h, x:x+w]\n",
    "    # eyes = eye_casecade.detectMultiScale(roi_gray)\n",
    "    # for (ex, ey, ew, eh) in eyes:\n",
    "    #     cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh),(0,255,0),2)\n",
    "\n",
    "cv2.imshow('cropped/ 12.jpg', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼굴 여러장 Crop 하여 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.3.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-0dc7cfe4a78c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m635\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\dev\\\\eclipse-workspace\\\\Python_Basic\\\\faceCrawling\\\\sad+face+real+photo\\\\ '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.3.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_casecade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,635):\n",
    "    img = cv2.imread('C:\\\\dev\\\\eclipse-workspace\\\\Python_Basic\\\\faceCrawling\\\\sad+face+real+photo\\\\ ' + str(i) + '.jpg')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3,5)\n",
    "    \n",
    "    #imgNum  = 0\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped = img[y - int(h / 4):y + h + int(h / 4), x - int(w / 4):x + w + int(w / 4)]\n",
    "        # 이미지를 저장\n",
    "        if (cropped.shape[0] != 0) and (cropped.shape[1] != 0) and (cropped.shape[2] != 0):\n",
    "            if (cropped.shape[0]==cropped.shape[1]): #pixel이 정사각형이면 출력!\n",
    "                cv2.imwrite('cropped_sad/ '+ str(i) +'.jpg', cropped)\n",
    "        \n",
    "        else:\n",
    "            break\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        #imgNum += 1\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    \n",
    "\n",
    "        #cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0),2)\n",
    "        # roi_gray = gray[y:y+h, x:x+w]\n",
    "        # roi_color = img[y:y+h, x:x+w]\n",
    "        # eyes = eye_casecade.detectMultiScale(roi_gray)\n",
    "        # for (ex, ey, ew, eh) in eyes:\n",
    "        #     cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh),(0,255,0),2)\n",
    "\n",
    " #   cv2.imshow('Image view', img)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오류 확인 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4 check1\n",
      "4 check2\n",
      "4 check3\n",
      "(32, 225, 3)\n",
      "32 225 3\n",
      "완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_casecade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(4,5):\n",
    "    print(i)\n",
    "    img = cv2.imread('C:\\\\dev\\\\eclipse-workspace\\\\Python_Basic\\\\faceCrawling\\\\sad+facial+expression\\\\ ' + str(i) + '.jpg')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    print(i,\"check1\")\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3,5)\n",
    "    print(i,\"check2\")\n",
    "    #imgNum  = 0\n",
    "    print(i,\"check3\")\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped = img[y - int(h / 4):y + h + int(h / 4), x - int(w / 4):x + w + int(w / 4)]\n",
    "        # 이미지를 저장\n",
    "        print(cropped.shape)\n",
    "        print(cropped.shape[0],cropped.shape[1],cropped.shape[2])\n",
    "        if (cropped.shape[0] != 0) and (cropped.shape[1] != 0) and (cropped.shape[2] != 0):\n",
    "            if (cropped.shape[0]==cropped.shape[1]):\n",
    "                cv2.imwrite('cropped_sad3/ '+ str(i) +'.jpg', cropped)\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            break\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "        #imgNum += 1\n",
    "\n",
    "        \n",
    "    \n",
    "    print(\"완료\")\n",
    "\n",
    "        #cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0),2)\n",
    "        # roi_gray = gray[y:y+h, x:x+w]\n",
    "        # roi_color = img[y:y+h, x:x+w]\n",
    "        # eyes = eye_casecade.detectMultiScale(roi_gray)\n",
    "        # for (ex, ey, ew, eh) in eyes:\n",
    "        #     cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh),(0,255,0),2)\n",
    "\n",
    " #   cv2.imshow('Image view', img)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_casecade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,3):\n",
    "    print(i)\n",
    "    img = cv2.imread('sad+face+real+photo/ ' + str(i) + '.jpg')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    print(i,\"check1\")\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3,5)\n",
    "    print(i,\"check2\")\n",
    "    #imgNum  = 0\n",
    "    print(i,\"check3\")\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped = img[y - int(h / 4):y + h + int(h / 4), x - int(w / 4):x + w + int(w / 4)]\n",
    "        # 이미지를 저장\n",
    "        print(cropped.shape)\n",
    "        print(cropped.shape[0],cropped.shape[1],cropped.shape[2])\n",
    "        if (cropped.shape[0] != 0) and (cropped.shape[1] != 0) and (cropped.shape[2] != 0):\n",
    "            if (cropped.shape[0]==cropped.shape[1]):\n",
    "                cv2.imwrite('cropped_sad/ '+ str(i) +'.jpg', cropped)\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            break\n",
    "            \n",
    "\n",
    "        \n",
    "    \n",
    "    print(\"완료\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼굴 Crop 하여 저장2 (dlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 faces are detected.\n",
      "left, top, right, bottom: 54 <bound method PyCapsule.top of rectangle(54,102,141,189)> 141 189\n",
      "(87, 87, 3)\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2 #openCV library\n",
    "\n",
    "# dlib에 있는 정면 검출기로 입력 사진 img에서 얼굴을 검출하여 faces로 반환\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "img = cv2.imread('happy+facial+expression/ 1.jpg')\n",
    "faces = face_detector(img)\n",
    "\n",
    "#결과 출력 & 이미지에 해당 검출 부분들을 빨간색(bgr 순)박스로 표시 (굵기 2)\n",
    "print(\"{} faces are detected.\".format(len(faces)))\n",
    "for f in faces:\n",
    "    print(\"left, top, right, bottom:\", f.left(),f.top,f.right(),f.bottom())\n",
    "    #cv2.rectangle(img, (f.left(),f.top()), (f.right(), f.bottom()), (0,0,255), 2) #빨간네모\n",
    "\n",
    "win = dlib.image_window()\n",
    "win.set_image(img)\n",
    "win.add_overlay(faces)\n",
    "# cv2.imwrite(\"cropped_sad_dlib/ 2.jpg\",img) #결과를 저장\n",
    "cropped = img[f.top():f.bottom(),f.left():f.right()]\n",
    "cv2.imwrite(\"cropped_happy_dlib2/ 1.jpg\",cropped) #얼굴부분만 따로 저장\n",
    "print(cropped.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: dlib.fhog_object_detector, image: array, upsample_num_times: int=0) -> dlib.rectangles\n\nInvoked with: <dlib.fhog_object_detector object at 0x00000260E11FE8F0>, None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ae3952da9b53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1091\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'neutral+face+real+photo/a'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#결과 출력 & 이미지에 해당 검출 부분들을 빨간색(bgr 순)박스로 표시 (굵기 2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __call__(): incompatible function arguments. The following argument types are supported:\n    1. (self: dlib.fhog_object_detector, image: array, upsample_num_times: int=0) -> dlib.rectangles\n\nInvoked with: <dlib.fhog_object_detector object at 0x00000260E11FE8F0>, None"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2 #openCV library\n",
    "\n",
    "# dlib에 있는 정면 검출기로 입력 사진 img에서 얼굴을 검출하여 faces로 반환\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "for i in range(1,1091):\n",
    "    img = cv2.imread('neutral+face+real+photo/a' + str(i) + '.jpg')\n",
    "    faces = face_detector(img)\n",
    "\n",
    "    #결과 출력 & 이미지에 해당 검출 부분들을 빨간색(bgr 순)박스로 표시 (굵기 2)\n",
    "    #print(\"{} faces are detected.\".format(len(faces)))\n",
    "    for f in faces:\n",
    "        #print(\"left, top, right, bottom:\", f.left(),f.top,f.right(),f.bottom())\n",
    "        #cv2.rectangle(img, (f.left(),f.top()), (f.right(), f.bottom()), (0,0,255), 2) #빨간네모\n",
    "\n",
    "        win = dlib.image_window()\n",
    "        win.set_image(img)\n",
    "        win.add_overlay(faces)\n",
    "        # cv2.imwrite(\"cropped_sad_dlib/ 2.jpg\",img) #결과를 저장\n",
    "        cropped = img[f.top():f.bottom(),f.left():f.right()]\n",
    "        if (cropped.shape[0] != 0) and (cropped.shape[1] != 0) and (cropped.shape[2] != 0):\n",
    "            if (cropped.shape[0]==cropped.shape[1]): #pixel이 정사각형이면 출력!\n",
    "                cv2.imwrite(\"cropped_neutral2_dlib/n\" + str(i) + \".jpg\",cropped) #얼굴부분만 따로 저장\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "        #print(cropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,635):\n",
    "    img = cv2.imread('C:\\\\dev\\\\eclipse-workspace\\\\Python_Basic\\\\faceCrawling\\\\sad+facial+expression\\\\ ' + str(i) + '.jpg')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3,5)\n",
    "    \n",
    "    #imgNum  = 0\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped = img[y - int(h / 4):y + h + int(h / 4), x - int(w / 4):x + w + int(w / 4)]\n",
    "        # 이미지를 저장\n",
    "        if (cropped.shape[0] != 0) and (cropped.shape[1] != 0) and (cropped.shape[2] != 0):\n",
    "            #if (cropped.shape[0]==cropped.shape[1]): #pixel이 정사각형이면 출력!\n",
    "            cv2.imwrite('cropped_sad2/ '+ str(i) +'.jpg', cropped)\n",
    "        \n",
    "        else:\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일명 일괄변경 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 주어진 디렉토리에 있는 항목들의 이름을 담고 있는 리스트를 반환합니다.\n",
    "# 리스트는 임의의 순서대로 나열됩니다.\n",
    "file_path = 'googlCrawlingEmotionDataset2/sad_color'\n",
    "file_names = os.listdir(file_path)\n",
    "file_names\n",
    "\n",
    "i = 1\n",
    "for name in file_names:\n",
    "    src = os.path.join(file_path, name)\n",
    "    dst = '' + str(i) + 's.jpg'\n",
    "    dst = os.path.join(file_path, dst)\n",
    "    os.rename(src, dst)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 리사이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "for i in range(1,2):\n",
    "    src = cv2.imread(\"test/\" + str(i) + \".jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "    dst = cv2.resize(src, dsize=(48, 48), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    cv2.imwrite('test/a'+ str(i) +'.jpg', dst)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 흑백변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "for i in range(1,225):\n",
    "    face = cv2.imread(\"googleCrawlingEmotionDataset/happy_color/h\" + str(i) + \".jpg\")\n",
    "    gray_face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    cv2.imwrite('googleCrawlingEmotionDataset/happy_gray/h'+ str(i) +'g.jpg', gray_face)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
