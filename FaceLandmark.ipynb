{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴 랜드마크 출력(줄 형태)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: test\\ a.jpg\n",
      "Number of faces detected: 1\n",
      "Detection 0: Left: -107 Top: -107 Right: 780 Bottom: 781\n",
      "Part 0: (-5, 156), Part 1: (-7, 258) ...\n",
      "Processing file: test\\10h.jpg\n",
      "Number of faces detected: 1\n",
      "Detection 0: Left: -14 Top: 7 Right: 86 Bottom: 96\n",
      "Part 0: (-1, 20), Part 1: (-2, 33) ...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# The contents of this file are in the public domain. See LICENSE_FOR_EXAMPLE_PROGRAMS.txt\n",
    "#\n",
    "#   This example program shows how to find frontal human faces in an image and\n",
    "#   estimate their pose.  The pose takes the form of 68 landmarks.  These are\n",
    "#   points on the face such as the corners of the mouth, along the eyebrows, on\n",
    "#   the eyes, and so forth.\n",
    "#\n",
    "#   The face detector we use is made using the classic Histogram of Oriented\n",
    "#   Gradients (HOG) feature combined with a linear classifier, an image pyramid,\n",
    "#   and sliding window detection scheme.  The pose estimator was created by\n",
    "#   using dlib's implementation of the paper:\n",
    "#      One Millisecond Face Alignment with an Ensemble of Regression Trees by\n",
    "#      Vahid Kazemi and Josephine Sullivan, CVPR 2014\n",
    "#   and was trained on the iBUG 300-W face landmark dataset (see\n",
    "#   https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/):  \n",
    "#      C. Sagonas, E. Antonakos, G, Tzimiropoulos, S. Zafeiriou, M. Pantic. \n",
    "#      300 faces In-the-wild challenge: Database and results. \n",
    "#      Image and Vision Computing (IMAVIS), Special Issue on Facial Landmark Localisation \"In-The-Wild\". 2016.\n",
    "#   You can get the trained model file from:\n",
    "#   http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2.\n",
    "#   Note that the license for the iBUG 300-W dataset excludes commercial use.\n",
    "#   So you should contact Imperial College London to find out if it's OK for\n",
    "#   you to use this model file in a commercial product.\n",
    "#\n",
    "#\n",
    "#   Also, note that you can train your own models using dlib's machine learning\n",
    "#   tools. See train_shape_predictor.py to see an example.\n",
    "#\n",
    "#\n",
    "# COMPILING/INSTALLING THE DLIB PYTHON INTERFACE\n",
    "#   You can install dlib using the command:\n",
    "#       pip install dlib\n",
    "#\n",
    "#   Alternatively, if you want to compile dlib yourself then go into the dlib\n",
    "#   root folder and run:\n",
    "#       python setup.py install\n",
    "#\n",
    "#   Compiling dlib should work on any operating system so long as you have\n",
    "#   CMake installed.  On Ubuntu, this can be done easily by running the\n",
    "#   command:\n",
    "#       sudo apt-get install cmake\n",
    "#\n",
    "#   Also note that this example requires Numpy which can be installed\n",
    "#   via the command:\n",
    "#       pip install numpy\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import dlib\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# if len(sys.argv) != 3:\n",
    "#     print(\n",
    "#         \"Give the path to the trained shape predictor model as the first \"\n",
    "#         \"argument and then the directory containing the facial images.\\n\"\n",
    "#         \"For example, if you are in the python_examples folder then \"\n",
    "#         \"execute this program by running:\\n\"\n",
    "#         \"    ./face_landmark_detection.py shape_predictor_68_face_landmarks.dat ../examples/faces\\n\"\n",
    "#         \"You can download a trained facial shape predictor from:\\n\"\n",
    "#         \"    http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\")\n",
    "#     exit()\n",
    "\n",
    "# predictor_path = sys.argv[1]\n",
    "# faces_folder_path = sys.argv[2]\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "win = dlib.image_window()\n",
    "\n",
    "for f in glob.glob(os.path.join(\"test\", \"*.jpg\")):\n",
    "    print(\"Processing file: {}\".format(f))\n",
    "    img = dlib.load_rgb_image(f)\n",
    "\n",
    "    win.clear_overlay()\n",
    "    win.set_image(img)\n",
    "\n",
    "    # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
    "    # second argument indicates that we should upsample the image 1 time. This\n",
    "    # will make everything bigger and allow us to detect more faces.\n",
    "    dets = detector(img, 1)\n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "    for k, d in enumerate(dets):\n",
    "        print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "            k, d.left(), d.top(), d.right(), d.bottom()))\n",
    "        # Get the landmarks/parts for the face in box d.\n",
    "        shape = predictor(img, d)\n",
    "        print(\"Part 0: {}, Part 1: {} ...\".format(shape.part(0),\n",
    "                                                  shape.part(1)))\n",
    "        # Draw the face landmarks on the screen.\n",
    "        win.add_overlay(shape)\n",
    "#         cv2.imwrite(\"test/ a.jpg\",shape)\n",
    "\n",
    "    win.add_overlay(dets)\n",
    "    dlib.hit_enter_to_continue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴 랜드마크 출력(점 형태)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: test\\10h.jpg\n",
      "Number of faces detected: 1\n",
      "Detection 0: Left: -14 Top: 7 Right: 86 Bottom: 96\n",
      "68\n",
      "0 -2 40\n",
      "1 -4 66\n",
      "2 -2 90\n",
      "3 2 114\n",
      "4 12 136\n",
      "5 26 156\n",
      "6 44 174\n",
      "7 62 186\n",
      "8 84 190\n",
      "9 104 184\n",
      "10 120 170\n",
      "11 136 156\n",
      "12 152 138\n",
      "13 164 120\n",
      "14 172 100\n",
      "15 176 80\n",
      "16 180 56\n",
      "17 12 34\n",
      "18 28 28\n",
      "19 46 28\n",
      "20 64 34\n",
      "21 78 42\n",
      "22 112 42\n",
      "23 128 38\n",
      "24 142 34\n",
      "25 158 36\n",
      "26 170 42\n",
      "27 96 54\n",
      "28 94 72\n",
      "29 92 90\n",
      "30 92 108\n",
      "31 70 108\n",
      "32 78 112\n",
      "33 88 118\n",
      "34 98 114\n",
      "35 106 112\n",
      "36 34 44\n",
      "37 46 42\n",
      "38 58 44\n",
      "39 68 52\n",
      "40 56 52\n",
      "41 44 50\n",
      "42 118 56\n",
      "43 130 50\n",
      "44 140 50\n",
      "45 150 56\n",
      "46 142 58\n",
      "47 130 58\n",
      "48 46 122\n",
      "49 62 122\n",
      "50 76 124\n",
      "51 86 128\n",
      "52 98 126\n",
      "53 112 126\n",
      "54 124 128\n",
      "55 112 144\n",
      "56 96 152\n",
      "57 84 152\n",
      "58 74 150\n",
      "59 58 142\n",
      "60 50 124\n",
      "61 76 128\n",
      "62 86 132\n",
      "63 98 130\n",
      "64 120 130\n",
      "65 98 142\n",
      "66 86 144\n",
      "67 76 142\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-84256f47a8fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;31m# 무한 대기를 타고 있다가 ESC 키가 눌리면 빠져나와 다음 이미지를 검색한다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mESC_KEY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyWindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Face'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import dlib\n",
    "import glob\n",
    "import cv2  #opencv 사용\n",
    "\n",
    "#opencv에서 ESC 키입력 상수\n",
    "ESC_KEY = 27\n",
    "\n",
    "'''\n",
    "RGB > BGR or BGR > RGB 변환 \n",
    "dlib는 RGB 형태로 이미지를 사용하고\n",
    "openCV는 BGR 형태이므로 B와 R을 바꿔주는 함수가 필요하다.\n",
    "'''\n",
    "def swapRGB2BGR(rgb):\n",
    "    r, g, b = cv2.split(img)\n",
    "    bgr = cv2.merge([b,g,r])\n",
    "    return bgr\n",
    "'''\n",
    "매개변수가 3개여야 한다.\n",
    "'''\n",
    "if len(sys.argv) != 3:\n",
    "    print(\n",
    "        \"Give the path to the trained shape predictor model as the first \"\n",
    "        \"argument and then the directory containing the facial images.\\n\"\n",
    "        \"For example, if you are in the python_examples folder then \"\n",
    "        \"execute this program by running:\\n\"\n",
    "        \"    ./face_landmark_detection.py shape_predictor_68_face_landmarks.dat ../examples/faces\\n\"\n",
    "        \"You can download a trained facial shape predictor from:\\n\"\n",
    "        \"    http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\")\n",
    "    exit()\n",
    "\n",
    "# 랜드마크 파일 경로\n",
    "predictor_path = sys.argv[1]\n",
    "# 이미지 경로\n",
    "faces_folder_path = sys.argv[2]\n",
    "\n",
    "# 얼굴 인식용 클래스 생성 (기본 제공되는 얼굴 인식 모델 사용)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# 인식된 얼굴에서 랜드마크 찾기위한 클래스 생성 \n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# 이미지를 화면에 표시하기 위한 openCV 윈도 생성\n",
    "cv2.namedWindow('Face')\n",
    "\n",
    "# 두번째 매개변수로 지정한 폴더를 싹다 뒤져서 jpg파일을 찾는다. \n",
    "for f in glob.glob(os.path.join(\"test\", \"*.jpg\")):\n",
    "    print(\"Processing file: {}\".format(f))\n",
    "    \n",
    "    # 파일에서 이미지 불러오기\n",
    "    img = dlib.load_rgb_image(f)      \n",
    "    \n",
    "    #불러온 이미지 데이터를 R과 B를 바꿔준다.\n",
    "    cvImg = swapRGB2BGR(img)    \n",
    "    \n",
    "    #이미지를 두배로 키운다.\n",
    "    cvImg = cv2.resize(cvImg, None, fx=2, fy=2, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # 얼굴 인식 두번째 변수 1은 업샘플링을 한번 하겠다는 얘기인데\n",
    "    # 업샘플링을하면 더 많이 인식할 수 있다고 한다.\n",
    "    # 다만 값이 커질수록 느리고 메모리도 많이 잡아먹는다.\n",
    "    # 그냥 1이면 될 듯. \n",
    "    dets = detector(img, 1)\n",
    "\n",
    "    # 인식된 얼굴 개수 출력 \n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "    \n",
    "    # 이제부터 인식된 얼굴 개수만큼 반복하여 얼굴 윤곽을 표시할 것이다. \n",
    "    for k, d in enumerate(dets):\n",
    "        # k 얼굴 인덱스\n",
    "        # d 얼굴 좌표\n",
    "        print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "            k, d.left(), d.top(), d.right(), d.bottom()))\n",
    "\n",
    "        # 인식된 좌표에서 랜드마크 추출 \n",
    "        shape = predictor(img, d)\n",
    "        print(shape.num_parts)\n",
    "        # num_parts(랜드마크 구조체)를 하나씩 루프를 돌린다.\n",
    "        for i in range(0, shape.num_parts):\n",
    "            # 해당 X,Y 좌표를 두배로 키워 좌표를 얻고\n",
    "            x = shape.part(i).x*2\n",
    "            y = shape.part(i).y*2\n",
    "\n",
    "            # 좌표값 출력\n",
    "            print(str(i)+ \" \" +str(x) + \" \" + str(y))\n",
    "\n",
    "            # 이미지 랜드마크 좌표 지점에 인덱스(랜드마크번호, 여기선 i)를 putText로 표시해준다.\n",
    "            #cv2.putText(cvImg, str(i), (x, y), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 0.3, (0, 255, 0))\n",
    "            #for (x, y) in shape:\n",
    "            cv2.circle(cvImg, (x, y), 1, (0, 255, 0), 2)\n",
    "        # 랜드마크가 표시된 이미지를 openCV 윈도에 표시\n",
    "        cv2.imshow('Face', cvImg)\n",
    "        cv2.imwrite(\"test/result/a.jpg\",cvImg)\n",
    "#         img_num = 1\n",
    "#         cv2.imwrite(\"test/result/\" + img_num + \".jpg\",cvImg)\n",
    "        \n",
    "\n",
    "    # 무한 대기를 타고 있다가 ESC 키가 눌리면 빠져나와 다음 이미지를 검색한다.\n",
    "    while True:\n",
    "        if cv2.waitKey(0) == ESC_KEY:\n",
    "            break;\n",
    "cv2.destroyWindow('Face')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴 랜드마크 출력(숫자 형태)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: test/48\\1_0.jpg\n",
      "Number of faces detected: 1\n",
      "Detection 0: Left: 5 Top: 6 Right: 41 Bottom: 42\n",
      "68\n",
      "0 -4 30\n",
      "1 -4 44\n",
      "2 -4 56\n",
      "3 -2 70\n",
      "4 2 80\n",
      "5 10 90\n",
      "6 20 96\n",
      "7 32 98\n",
      "8 40 100\n",
      "9 48 98\n",
      "10 52 92\n",
      "11 56 84\n",
      "12 60 76\n",
      "13 64 68\n",
      "14 68 60\n",
      "15 70 52\n",
      "16 70 42\n",
      "17 16 28\n",
      "18 26 24\n",
      "19 34 24\n",
      "20 42 28\n",
      "21 50 30\n",
      "22 58 32\n",
      "23 62 30\n",
      "24 66 30\n",
      "25 70 30\n",
      "26 72 32\n",
      "27 54 38\n",
      "28 54 44\n",
      "29 56 52\n",
      "30 56 58\n",
      "31 44 64\n",
      "32 48 64\n",
      "33 52 66\n",
      "34 54 66\n",
      "35 56 64\n",
      "36 26 34\n",
      "37 30 32\n",
      "38 36 32\n",
      "39 40 36\n",
      "40 36 38\n",
      "41 30 36\n",
      "42 56 38\n",
      "43 60 36\n",
      "44 64 36\n",
      "45 68 38\n",
      "46 64 40\n",
      "47 60 40\n",
      "48 34 78\n",
      "49 40 76\n",
      "50 46 74\n",
      "51 50 76\n",
      "52 52 74\n",
      "53 54 76\n",
      "54 54 80\n",
      "55 52 82\n",
      "56 50 84\n",
      "57 48 86\n",
      "58 44 84\n",
      "59 38 82\n",
      "60 36 78\n",
      "61 46 78\n",
      "62 48 78\n",
      "63 52 78\n",
      "64 52 80\n",
      "65 52 80\n",
      "66 48 80\n",
      "67 46 80\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-15238e97948f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;31m# 무한 대기를 타고 있다가 ESC 키가 눌리면 빠져나와 다음 이미지를 검색한다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mESC_KEY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyWindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Face'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import dlib\n",
    "import glob\n",
    "import cv2  #opencv 사용\n",
    "\n",
    "#opencv에서 ESC 키입력 상수\n",
    "ESC_KEY = 27\n",
    "\n",
    "'''\n",
    "RGB > BGR or BGR > RGB 변환 \n",
    "dlib는 RGB 형태로 이미지를 사용하고\n",
    "openCV는 BGR 형태이므로 B와 R을 바꿔주는 함수가 필요하다.\n",
    "'''\n",
    "def swapRGB2BGR(rgb):\n",
    "    r, g, b = cv2.split(img)\n",
    "    bgr = cv2.merge([b,g,r])\n",
    "    return bgr\n",
    "'''\n",
    "매개변수가 3개여야 한다.\n",
    "'''\n",
    "if len(sys.argv) != 3:\n",
    "    print(\n",
    "        \"Give the path to the trained shape predictor model as the first \"\n",
    "        \"argument and then the directory containing the facial images.\\n\"\n",
    "        \"For example, if you are in the python_examples folder then \"\n",
    "        \"execute this program by running:\\n\"\n",
    "        \"    ./face_landmark_detection.py shape_predictor_68_face_landmarks.dat ../examples/faces\\n\"\n",
    "        \"You can download a trained facial shape predictor from:\\n\"\n",
    "        \"    http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\")\n",
    "    exit()\n",
    "\n",
    "# 랜드마크 파일 경로\n",
    "predictor_path = sys.argv[1]\n",
    "# 이미지 경로\n",
    "faces_folder_path = sys.argv[2]\n",
    "\n",
    "# 얼굴 인식용 클래스 생성 (기본 제공되는 얼굴 인식 모델 사용)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# 인식된 얼굴에서 랜드마크 찾기위한 클래스 생성 \n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# 이미지를 화면에 표시하기 위한 openCV 윈도 생성\n",
    "cv2.namedWindow('Face')\n",
    "\n",
    "# 두번째 매개변수로 지정한 폴더를 싹다 뒤져서 jpg파일을 찾는다. \n",
    "for f in glob.glob(os.path.join(\"test/48\", \"*.jpg\")):\n",
    "    print(\"Processing file: {}\".format(f))\n",
    "    \n",
    "    # 파일에서 이미지 불러오기\n",
    "    img = dlib.load_rgb_image(f)      \n",
    "    \n",
    "    #불러온 이미지 데이터를 R과 B를 바꿔준다.\n",
    "    cvImg = swapRGB2BGR(img)    \n",
    "    \n",
    "    #이미지를 두배로 키운다.\n",
    "    cvImg = cv2.resize(cvImg, None, fx=2, fy=2, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # 얼굴 인식 두번째 변수 1은 업샘플링을 한번 하겠다는 얘기인데\n",
    "    # 업샘플링을하면 더 많이 인식할 수 있다고 한다.\n",
    "    # 다만 값이 커질수록 느리고 메모리도 많이 잡아먹는다.\n",
    "    # 그냥 1이면 될 듯. \n",
    "    dets = detector(img, 1)\n",
    "\n",
    "    # 인식된 얼굴 개수 출력 \n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "    \n",
    "    # 이제부터 인식된 얼굴 개수만큼 반복하여 얼굴 윤곽을 표시할 것이다. \n",
    "    for k, d in enumerate(dets):\n",
    "        # k 얼굴 인덱스\n",
    "        # d 얼굴 좌표\n",
    "        print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "            k, d.left(), d.top(), d.right(), d.bottom()))\n",
    "\n",
    "        # 인식된 좌표에서 랜드마크 추출 \n",
    "        shape = predictor(img, d)\n",
    "        print(shape.num_parts)\n",
    "        # num_parts(랜드마크 구조체)를 하나씩 루프를 돌린다.\n",
    "        for i in range(0, shape.num_parts):\n",
    "            # 해당 X,Y 좌표를 두배로 키워 좌표를 얻고\n",
    "            x = shape.part(i).x*2\n",
    "            y = shape.part(i).y*2\n",
    "\n",
    "            # 좌표값 출력\n",
    "            print(str(i)+ \" \" +str(x) + \" \" + str(y))\n",
    "\n",
    "            # 이미지 랜드마크 좌표 지점에 인덱스(랜드마크번호, 여기선 i)를 putText로 표시해준다.\n",
    "            cv2.putText(cvImg, str(i), (x, y), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 0.3, (0, 255, 0))                    \n",
    "        # 랜드마크가 표시된 이미지를 openCV 윈도에 표시\n",
    "        cv2.imshow('Face', cvImg)\n",
    "        cv2.imwrite(\"test/result3/a.jpg\",cvImg)\n",
    "\n",
    "    # 무한 대기를 타고 있다가 ESC 키가 눌리면 빠져나와 다음 이미지를 검색한다.\n",
    "    while True:\n",
    "        if cv2.waitKey(0) == ESC_KEY:\n",
    "            break;\n",
    "cv2.destroyWindow('Face')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴 랜드마크 여러장 출력(점 형태)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: 1\n",
      "Number of faces detected: 1\n",
      "68\n",
      "0 7 16\n",
      "1 6 25\n",
      "2 7 34\n",
      "3 8 43\n",
      "4 10 51\n",
      "5 14 59\n",
      "6 20 66\n",
      "7 27 71\n",
      "8 36 71\n",
      "9 45 70\n",
      "10 51 66\n",
      "11 57 60\n",
      "12 61 52\n",
      "13 65 45\n",
      "14 68 36\n",
      "15 69 27\n",
      "16 69 18\n",
      "17 12 13\n",
      "18 15 9\n",
      "19 21 9\n",
      "20 27 10\n",
      "21 32 13\n",
      "22 44 12\n",
      "23 49 9\n",
      "24 55 7\n",
      "25 61 7\n",
      "26 64 10\n",
      "27 39 18\n",
      "28 39 24\n",
      "29 39 30\n",
      "30 39 37\n",
      "31 32 40\n",
      "32 36 41\n",
      "33 39 42\n",
      "34 42 41\n",
      "35 45 40\n",
      "36 18 19\n",
      "37 22 16\n",
      "38 26 16\n",
      "39 29 19\n",
      "40 26 20\n",
      "41 21 21\n",
      "42 47 19\n",
      "43 51 15\n",
      "44 55 15\n",
      "45 58 17\n",
      "46 56 19\n",
      "47 52 20\n",
      "48 27 53\n",
      "49 31 52\n",
      "50 35 51\n",
      "51 38 52\n",
      "52 42 51\n",
      "53 46 51\n",
      "54 49 52\n",
      "55 45 55\n",
      "56 42 57\n",
      "57 38 58\n",
      "58 34 58\n",
      "59 30 56\n",
      "60 28 54\n",
      "61 35 53\n",
      "62 38 53\n",
      "63 42 52\n",
      "64 47 52\n",
      "65 42 53\n",
      "66 38 54\n",
      "67 34 54\n",
      "Processing file: 2\n",
      "Number of faces detected: 1\n",
      "68\n",
      "0 20 43\n",
      "1 14 54\n",
      "2 10 66\n",
      "3 8 80\n",
      "4 8 93\n",
      "5 12 106\n",
      "6 17 117\n",
      "7 24 126\n",
      "8 38 131\n",
      "9 55 133\n",
      "10 72 132\n",
      "11 90 129\n",
      "12 105 123\n",
      "13 117 113\n",
      "14 123 100\n",
      "15 128 86\n",
      "16 133 72\n",
      "17 26 28\n",
      "18 31 21\n",
      "19 40 17\n",
      "20 49 18\n",
      "21 58 23\n",
      "22 79 27\n",
      "23 91 25\n",
      "24 105 29\n",
      "25 115 39\n",
      "26 121 51\n",
      "27 63 38\n",
      "28 59 43\n",
      "29 54 49\n",
      "30 50 54\n",
      "31 41 64\n",
      "32 45 66\n",
      "33 50 69\n",
      "34 58 69\n",
      "35 66 70\n",
      "36 32 40\n",
      "37 38 38\n",
      "38 44 39\n",
      "39 50 42\n",
      "40 43 41\n",
      "41 37 40\n",
      "42 82 48\n",
      "43 90 48\n",
      "44 97 50\n",
      "45 103 54\n",
      "46 95 52\n",
      "47 89 50\n",
      "48 25 86\n",
      "49 32 79\n",
      "50 42 78\n",
      "51 50 81\n",
      "52 58 81\n",
      "53 72 87\n",
      "54 84 98\n",
      "55 69 109\n",
      "56 54 111\n",
      "57 45 109\n",
      "58 37 107\n",
      "59 28 99\n",
      "60 27 86\n",
      "61 41 82\n",
      "62 49 84\n",
      "63 57 86\n",
      "64 81 97\n",
      "65 56 105\n",
      "66 47 103\n",
      "67 39 101\n",
      "Processing file: 3\n",
      "Number of faces detected: 1\n",
      "68\n",
      "0 12 7\n",
      "1 8 21\n",
      "2 6 36\n",
      "3 5 50\n",
      "4 8 64\n",
      "5 12 78\n",
      "6 19 90\n",
      "7 28 99\n",
      "8 39 102\n",
      "9 51 103\n",
      "10 62 97\n",
      "11 72 89\n",
      "12 80 80\n",
      "13 88 69\n",
      "14 93 57\n",
      "15 98 45\n",
      "16 101 33\n",
      "17 23 8\n",
      "18 30 3\n",
      "19 40 5\n",
      "20 48 10\n",
      "21 55 16\n",
      "22 71 21\n",
      "23 80 19\n",
      "24 88 19\n",
      "25 95 22\n",
      "26 98 29\n",
      "27 61 29\n",
      "28 58 38\n",
      "29 56 48\n",
      "30 54 57\n",
      "31 42 57\n",
      "32 46 60\n",
      "33 51 63\n",
      "34 56 63\n",
      "35 61 62\n",
      "36 32 20\n",
      "37 38 19\n",
      "38 44 20\n",
      "39 48 26\n",
      "40 42 26\n",
      "41 36 24\n",
      "42 71 32\n",
      "43 77 29\n",
      "44 83 30\n",
      "45 87 34\n",
      "46 82 36\n",
      "47 76 34\n",
      "48 31 70\n",
      "49 38 70\n",
      "50 44 71\n",
      "51 47 73\n",
      "52 52 73\n",
      "53 57 76\n",
      "54 62 78\n",
      "55 55 83\n",
      "56 49 84\n",
      "57 44 84\n",
      "58 40 82\n",
      "59 35 78\n",
      "60 34 71\n",
      "61 43 75\n",
      "62 47 76\n",
      "63 51 76\n",
      "64 59 78\n",
      "65 51 77\n",
      "66 46 77\n",
      "67 42 75\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import dlib\n",
    "import glob\n",
    "import cv2  #opencv 사용\n",
    "\n",
    "#opencv에서 ESC 키입력 상수\n",
    "ESC_KEY = 27\n",
    "\n",
    "'''\n",
    "RGB > BGR or BGR > RGB 변환 \n",
    "dlib는 RGB 형태로 이미지를 사용하고\n",
    "openCV는 BGR 형태이므로 B와 R을 바꿔주는 함수가 필요하다.\n",
    "'''\n",
    "def swapRGB2BGR(rgb):\n",
    "    r, g, b = cv2.split(img)\n",
    "    bgr = cv2.merge([b,g,r])\n",
    "    return bgr\n",
    "'''\n",
    "매개변수가 3개여야 한다.\n",
    "'''\n",
    "if len(sys.argv) != 3:\n",
    "    print(\n",
    "        \"Give the path to the trained shape predictor model as the first \"\n",
    "        \"argument and then the directory containing the facial images.\\n\"\n",
    "        \"For example, if you are in the python_examples folder then \"\n",
    "        \"execute this program by running:\\n\"\n",
    "        \"    ./face_landmark_detection.py shape_predictor_68_face_landmarks.dat ../examples/faces\\n\"\n",
    "        \"You can download a trained facial shape predictor from:\\n\"\n",
    "        \"    http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\")\n",
    "    exit()\n",
    "\n",
    "# 랜드마크 파일 경로\n",
    "predictor_path = sys.argv[1]\n",
    "# 이미지 경로\n",
    "faces_folder_path = sys.argv[2]\n",
    "\n",
    "# 얼굴 인식용 클래스 생성 (기본 제공되는 얼굴 인식 모델 사용)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# 인식된 얼굴에서 랜드마크 찾기위한 클래스 생성 \n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# 이미지를 화면에 표시하기 위한 openCV 윈도 생성\n",
    "cv2.namedWindow('Face')\n",
    "\n",
    "# 두번째 매개변수로 지정한 폴더를 싹다 뒤져서 jpg파일을 찾는다. \n",
    "for f in range(1,4):\n",
    "    print(\"Processing file: {}\".format(f))\n",
    "    \n",
    "    # 파일에서 이미지 불러오기\n",
    "    img = cv2.imread(\"test/dudes/\" + str(f) + \".jpg\", cv2.IMREAD_COLOR)    \n",
    "    \n",
    "    #불러온 이미지 데이터를 R과 B를 바꿔준다.\n",
    "    #cvImg = swapRGB2BGR(img)\n",
    "    cvImg = img\n",
    "    \n",
    "    #이미지를 두배로 키운다.\n",
    "    cvImg = cv2.resize(cvImg, None, fx=1, fy=1, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    \n",
    "    # 얼굴 인식 두번째 변수 1은 업샘플링을 한번 하겠다는 얘기인데\n",
    "    # 업샘플링을하면 더 많이 인식할 수 있다고 한다.\n",
    "    # 다만 값이 커질수록 느리고 메모리도 많이 잡아먹는다.\n",
    "    # 그냥 1이면 될 듯. \n",
    "    dets = detector(img, 1)\n",
    "\n",
    "    # 인식된 얼굴 개수 출력 \n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "    \n",
    "    # 이제부터 인식된 얼굴 개수만큼 반복하여 얼굴 윤곽을 표시할 것이다. \n",
    "    for k, d in enumerate(dets):\n",
    "        # k 얼굴 인덱스\n",
    "        # d 얼굴 좌표\n",
    "#         print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "#             k, d.left(), d.top(), d.right(), d.bottom()))\n",
    "\n",
    "        # 인식된 좌표에서 랜드마크 추출 \n",
    "        shape = predictor(img, d)\n",
    "        print(shape.num_parts)\n",
    "        # num_parts(랜드마크 구조체)를 하나씩 루프를 돌린다.\n",
    "        for i in range(0, shape.num_parts):\n",
    "            # 해당 X,Y 좌표를 두배로 키워 좌표를 얻고\n",
    "            x = shape.part(i).x*1\n",
    "            y = shape.part(i).y*1\n",
    "\n",
    "            # 좌표값 출력\n",
    "            print(str(i)+ \" \" +str(x) + \" \" + str(y))\n",
    "\n",
    "            # 이미지 랜드마크 좌표 지점에 인덱스(랜드마크번호, 여기선 i)를 putText로 표시해준다.\n",
    "            #cv2.putText(cvImg, str(i), (x, y), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 0.3, (0, 255, 0))\n",
    "            #for (x, y) in shape:\n",
    "            cv2.circle(cvImg, (x, y), 1, (255, 255, 255), 2)\n",
    "        # 랜드마크가 표시된 이미지를 openCV 윈도에 표시\n",
    "        cv2.imshow('Face', cvImg)\n",
    "        cv2.imwrite(\"test/result4/\" + str(f) + \".jpg\",cvImg)\n",
    "#         img_num = 1\n",
    "#         cv2.imwrite(\"test/result/\" + img_num + \".jpg\",cvImg)\n",
    "        \n",
    "\n",
    "    # 무한 대기를 타고 있다가 ESC 키가 눌리면 빠져나와 다음 이미지를 검색한다.\n",
    "    while True:\n",
    "        if cv2.waitKey(0) == ESC_KEY:\n",
    "            break;\n",
    "cv2.destroyWindow('Face')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
